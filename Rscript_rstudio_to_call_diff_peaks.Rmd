---
title: "diff_peaks_test"
output: html_notebook
---


## ** First I want to get into the correct dir from when i launch the eureka Rstudio ** 
```{r}

# do not need this part if you are using this script in nextflow or using files from your own dir
# only used if eureka starts you off at your username dir
#current_dir = getwd()

# this might not work if the script is already in the dir that you want it to be
#peak_project_dir = paste0(current_dir, "/pipelines/peak_calling_analysis_pipeline")

#setwd(current_dir)

```

## Load libraries

```{r}
library(DESeq2)
library(tidyr)
```
```{r}
library(GenomicRanges)

# after making my new conda R environment 3, it worked to load chromVAR in the CLI but not in Rstudio eureka.
# so i installed conda install conda-forge::gsl in the conda env and everything worked
library(chromVAR)
```


### now to get the list of peak files from H3k27me3

```{r}
# this will allow me to list all of the files in the directories

expr_condition_peak_list = list.files(path="./peak_files/", pattern="*H3k27me3*", recursive = TRUE, full.names = TRUE)

# now to create a for loop that will read all of the files and put them into a grange object

# these will be the master peaks

mPeak = GRanges()

for (file in expr_condition_peak_list) {
  
  
  #file_path = paste0("./peak_files", file)
  peakRes = read.table(file, header = FALSE, fill = TRUE )
  
  # the peak files generated by macs2 will have the first row as description stuff, so I needed to remove it
  # so IRanges can have the start and stop as numeric. Which I also modified from the tutorial I looked at
  peakRes = peakRes[-1,]
  
  # modified this to makesure the start and stop are seen as numeric.
  mPeak = GRanges( seqnames = peakRes$V1, IRanges(start = as.numeric(peakRes$V2), end = as.numeric(peakRes$V3)), strand = "*") %>% append(mPeak, .)
}

masterPeak = reduce(mPeak)

```


## now getting the fragments from the bam files to see how many align to each peak in the master peak list


```{r}


# getting only the bam files from the directory that has bams and index(bai) files
bamDir_bamlist = list.files(path = "./bam_files/", pattern = "*H3k27me3.*bam$", full.names=TRUE)

# to make this automated I should change it from k27me3_peak_list to expr_condition_peak_list
countmatrix = matrix(NA, length(masterPeak), length(expr_condition_peak_list))


# just loop throught the bam list and get the counts for that bams fragments in the masterpeaks then use the strsplit to make the column name

num_of_files = c(1:length(bamDir_bamlist))

expr_names_in_order = list()

# for deseq2 i need the condition design. so hlow and scrm
# then i will find a way to tally how many of each are there so i can automate the rep count
condition_design = list()

type_design = list()

for (x in num_of_files) {
  
  # need to get the path to the bamfile so we are using this bam file
  path_bamfile = bamDir_bamlist[x]
  
  #getting the tokens of that bam file so we can create the correct column name from the bam that the counts came from 
  bam_tokens = strsplit(basename(bamDir_bamlist[x]), split = "_")[[1]]
  
  # labeling the important tokens so it is easier to keep track of
  condition = bam_tokens[1]
  histone = bam_tokens[2]
  replicate = bam_tokens[3]
  
  # for later parts I need the condition and to know how many times to repeat them
  condition_design = append(condition_design, paste(condition,histone,sep="_"))
  
  # also get the replicate too for type design
  type_design = append(type_design, replicate)
  
  # using the library chromVAR to get the fragments in the master peak list
  fragment_counts = getCounts(path_bamfile, masterPeak, paired=TRUE, by_rg =FALSE, format = "bam")
  
  # this puts the counts from the object (fragment_counts) in the current matrix column based on the for loop
  countmatrix[,x] = counts(fragment_counts)[,1]
  
  # checking to see that the bam file is the same as its conditions histone tokens
  print(paste(condition, histone, replicate, sep="_"))
  
  
  #making a basic file name with these three tokens that will be the column labels
  file_name = paste(condition, histone, replicate, sep="_")
  
  
  # appending them to a list in the order the columns were made, to then just put the names as column names.
 expr_names_in_order = append(expr_names_in_order, file_name)
  
}

# now taking those names that were made from the tokens and making them the colnames for the matrix. but i wanted to make sure they were the correct names assigned to the correct columns.
colnames(countmatrix) = expr_names_in_order

#colnames()

#paste(rep("histL", 2), rep("repL", each = 2), sep = "_")





```
```{r}

# I want to get the chr start end of the peaks and put them in the matrix as column names so I know which peaks I am looking at from the deseq2 results in the differential peaks.
seqnames(masterPeak)

# i should put the unique ids from the master peak object in the matrix as row names.
unique_masterPeak_ids = paste0(as.character(seqnames(masterPeak)), ":" ,start(masterPeak), "-", end(masterPeak))

rownames(countmatrix) = unique_masterPeak_ids

head(countmatrix)
tail(countmatrix)
```


## now to get the matrix into deseq2

```{r}

#first removing the low count fragments. only keeping the rows that are above 5 count in total

keep_Rows = which(rowSums(countmatrix) > 5)

filt_countmatrix = countmatrix[keep_Rows,]

# now to get the condition_design
condition_counts = table(unlist(condition_design))

# this gives back the names and the counts give back the counts for each of the names
condition_names = names(condition_counts)
condition_num = as.numeric(condition_counts)

# now i can put both lists in to get back the experiment design
condition_factor = factor(rep(condition_names, times=condition_num))

# repeating the above to have another column with type (replicates)
type_counts = table(unlist(type_design))
type_names = names(type_counts)
#type_num = as.numeric(type_counts)

type_factor = factor(rep(type_names, times=length(condition_names)))



# now to do the normal deseq2 workflow

dds = DESeqDataSetFromMatrix(countData = filt_countmatrix,
                             colData = DataFrame(condition_factor, type_factor),
                             design = ~ condition_factor)

# using the function on our data
DDS = DESeq(dds)

norm_DDS = counts(DDS, normalized = TRUE) # normalization with respect to the sequencing depth

# adding _norm onto the column names in the normalized matrix
colnames(norm_DDS) = paste0(colnames(norm_DDS), "_norm")


# provides independent filtering using the mean of normalized counts
res = results(DDS, independentFiltering = FALSE, altHypothesis = "greaterAbs")


# this is looking at the differences between the 3 deseq analyzed options
countMatDiff = cbind(filt_countmatrix, norm_DDS, res)

head(countMatDiff)

#- countMatDiff summarizes the differential analysis results: 
#  - First 4 columns: raw reads counts after filtering the peak regions with low counts
#  - Second 4 columns: normalized read counts eliminating library size difference.
#  - Remaining columns: differential detection results.


```

## continuing with the deseq2 documentation

```{r}


# getting the results name and addding to the coef we want to shrink
experiment_design_name = resultsNames(DDS)[2]

# useful for visualization and ranking of genes or in this case peaks
resLFC = lfcShrink(DDS, coef= resultsNames(DDS)[2], type = "apeglm")

# looking at the resLFC lfc shrink to see how many have a pvalue < 0.05

#res_05 = results(DDS, alpha = 0.05)

# this is just the number of peaks that are less than 0.05 pvalue
resLFC_05 = sum(resLFC$pvalue<0.05, na.rm=TRUE)


# i want to order the padj so we have the most significant at the top of the data

resLFC_padj_ordered = resLFC[order(resLFC$padj),]

write.table(as.data.frame(resLFC_padj_ordered), file = paste0(experiment_design_name,".tsv"), sep = "\t")

```

# it is useful to work with transformed versions of the count data for downstream visualization

### * see the 'Data transformations and visualization Count data transformations' section of DESeq2 documentation

```{r}
# using rlog over vst for transformation

rld = rlog(DDS, blind=FALSE)

#it is clear that the rlog transformation inherently accounts for differences in sequencing depth *
head(assay(rld), 5)



```


## now we need to conduct quality control of the data to determine which samples may be detrimental to us finding differential peaks.

```{r}
# using the rlog transformed data because of its ability to visualize our data better than raw counts; we will make a heatmap to show this

library("pheatmap")
select <- order(rowMeans(counts(DDS,normalized=TRUE)),
                decreasing=TRUE)[1:20] # checking the top 3000 peaks with the most counts

# making a df with only the column condition names
df <- as.data.frame(colData(DDS)[,"condition_factor"])

# now using the rld (rlog) transformed values

heatmap_row_avg = pheatmap(assay(rld)[select,], cluster_rows=FALSE, show_rownames=FALSE,
         cluster_cols=FALSE, main = "top20 rowMeans heatmap" )

heatmap_row_avg

pdf(file = paste(experiment_design_name,"top20_rowMeans_plot.pdf", sep = "_"), width = 10, height = 10)
heatmap_row_avg
dev.off()

# I dont see big differences in the heatmap when looking at most of the peaks together >3000
# but when looking at 20 peaks with the highest row counts across the samples we see that the hlow and scrm are different from eachother but not much differences in each condition.

```


## lets check how the samples cluster also 

```{r}

sampleDists <- dist(t(assay(rld)))

library("RColorBrewer")
sampleDistMatrix <- as.matrix(sampleDists)
#rownames(sampleDistMatrix) <- rld$condition_factor
#colnames(sampleDistMatrix) <- NULL
colors <- colorRampPalette( rev(brewer.pal(9, "Blues")) )(255)
heatmap_cluster = pheatmap(sampleDistMatrix,
         clustering_distance_rows=sampleDists,
         clustering_distance_cols=sampleDists,
         col=colors, main = "Dist Cluster plot")

pdf(file = paste(experiment_design_name,"Dist_Cluster_plot.pdf", sep = "_"), width = 10, height = 10)
heatmap_cluster
dev.off()

# we see here that the conditions cluster with each-other and do not mix, when using hclust based on distance

```
## now using a pca plot to better visualize the samples in a 2d plane and to get an idea of any batch effects

```{r}

library(ggplot2)

pcaData = plotPCA(rld, intgroup=c("condition_factor","type_factor"), returnData = TRUE )
pcaData

percentVar <- round(100 * attr(pcaData, "percentVar"))


pca_plot_rlog = ggplot(pcaData, aes(PC1, PC2, color=condition_factor, shape=type_factor)) +
  ggtitle("PCA plot using Rlog transform") +
  geom_point(size=3) +
  xlab(paste0("PC1: ",percentVar[1],"% variance")) +
  ylab(paste0("PC2: ",percentVar[2],"% variance")) + 
  coord_fixed()
pca_plot

png(filename = paste(experiment_design_name,"PCA_plot_rlog.png", sep = "_"), width = 1000, height = 1000, antialias = "subpixel")
pca_plot_rlog
dev.off()


pdf(file = paste(experiment_design_name,"PCA_plot_rlog.pdf", sep = "_"), width = 10, height = 10)
pca_plot_rlog
dev.off()

# when using rlog transformation, I see that the only outlier is hlow r3. and remember, the deseq2 documentation states that rlog transformation accounts for differences in library sequencing depth.

```

## testing the pca plot without transforming with rlog or vst

```{r}

vsd_t = vst(DDS, blind = FALSE)
head(assay(vsd_t), 5)

pcaData2 = plotPCA(vsd_t, intgroup=c("condition_factor","type_factor"), returnData = TRUE )
pcaData2

percentVar <- round(100 * attr(pcaData2, "percentVar"))
pca_plot_vst = ggplot(pcaData2, aes(PC1, PC2, color=condition_factor, shape=type_factor)) +
  ggtitle("PCA plot using VST transform") +
  geom_point(size=3) +
  xlab(paste0("PC1: ",percentVar[1],"% variance")) +
  ylab(paste0("PC2: ",percentVar[2],"% variance")) + 
  coord_fixed()

pca_plot_vst

pdf(file = paste(experiment_design_name,"PCA_plot_vst.pdf", sep = "_"), width = 10, height = 10)
pca_plot_vst
dev.off()

png(file = paste(experiment_design_name,"PCA_plot_vst.png", sep = "_"), width = 1000, height = 1000)
pca_plot_vst
dev.off()

# when transforming with vst i see scrm r1 and hlow r3 are the outliers for their respective conditions
```

## I want to automate choosing and extracting the replicate that has high contribution to the variance

```{r}

# lets use rlog
pca_scores_rlog_control = pcaData2[1:3,1:2]
pca_scores_rlog_treatment = pcaData2[4:6,1:2]

#pca_scores_rlog
# getting the centroid between the pca for each replicate
rlog_centroid_control = colMeans(pca_scores_rlog_control)
rlog_centroid_treatment = colMeans(pca_scores_rlog_treatment)

# Compute Euclidean distances
distances_control <- apply(pca_scores_rlog_control, 1, function(coord) sqrt(sum((coord - rlog_centroid_control)^2)))
distances_treatment <- apply(pca_scores_rlog_treatment, 1, function(coord) sqrt(sum((coord - rlog_centroid_treatment)^2)))

# Identify the replicate with the highest distance
high_var_replicate_control <- names(which.max(distances_control))
high_var_replicate_treatment <- names(which.max(distances_treatment))
print(paste("High variance replicate is:", high_var_replicate_control, high_var_replicate_treatment))

```





# now to visualize the differential peaks with MA-plot and volcano plots

```{r}

# I want to plot this and title it the name of the condition

plotMA(resLFC, ylim=c(-5,5), main = paste0(resultsNames(DDS)[2], " ", "apeglm"))
abline( h=-2:2, col="orange")
#idx <- identify(resLFC$baseMean, resLFC$log2FoldChange)
#rownames(resLFC)[idx]


```








## dont need to do this.

```{r}

# getting only the bam files from the directory that has bams and index(bai) files
bamDir_bamlist = list.files(path = "./bam_files/", pattern = "*H3k27me3.*bam$", full.names=TRUE)

# to make this automated I should change it from k27me3_peak_list to expr_condition_peak_list
countmatrix = matrix(NA, length(masterPeak), length(expr_condition_peak_list))


# i want to split the string and see if H3k27me3 and r1 are equal to that in the peaklist

bam_str_split = strsplit(basename(bamDir_bamlist[1]), split = "_")[[1]]

condition_peak_split = strsplit(basename(expr_condition_peak_list[1]), split = "_")[[1]]

# in this list tokens 2 and 3 are the histone and replicate. if these are the same then i have the correct bam file with the correct peak file
condition_peak_split[2:3]

# just testing
bam_str_split[2:3] == condition_peak_split[2:3]


c(1:length(expr_condition_peak_list))

# are the lists ordered?
# yes so since we will have the same number of bam files with the same number of peak files just loop through that range
expr_condition_peak_list
bamDir_bamlist

num_of_files = c(1:length(bamDir_bamlist)

for (x in num_of_files) {
  
  # can still check if the are in the same order
  bam_str_split = strsplit(basename(bamDir_bamlist[x]), split = "_")[[1]]
  condition_peak_split = strsplit(basename(expr_condition_peak_list[x]), split = "_")[[1]]
  # so now see if these share the same histone and rep
  if (bam_str_split[2:3] == condition_peak_split[2:3]) {
    
    getCounts(bamDir_bamlist[x], )
  }
  
  
  
  
  
  
}




```

